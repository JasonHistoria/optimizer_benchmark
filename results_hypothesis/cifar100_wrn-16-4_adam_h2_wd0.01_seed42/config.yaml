augmentation: strong
batch_size: 128
data_fraction: 1.0
early_stop: 0
epochs: 50
exp_suffix: _h2_wd0.01
grad_clip: 0
label_smoothing: 0.1
lr: 0.001
model: wrn-16-4
optimizer: adam
save_dir: ./results_hypothesis
scheduler: cosine
seed: 42
weight_decay: 0.01
workers: 4
