{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer Comparison Experiments\n",
    "## CSE 493S Project - Systematic Comparison of Optimization Algorithms\n",
    "\n",
    "**Team Members:** Jinghao Liu, Xuan Zhang, Yuzheng Zhang\n",
    "\n",
    "This notebook contains the code to run optimizer comparison experiments on CIFAR-10 and CIFAR-100.\n",
    "\n",
    "**Optimizers tested:**\n",
    "- SGD with Momentum\n",
    "- Adam\n",
    "- AdamW\n",
    "- RAdam\n",
    "- Lion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running on Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"\u2713 Running on Google Colab\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"\u2713 Running locally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for Colab\n",
    "if IN_COLAB:\n",
    "    # Clone repository (replace with your repo URL)\n",
    "    !git clone https://github.com/JasonHistoria/optimizer_benchmark.git\n",
    "    %cd optimizer_benchmark\n",
    "    \n",
    "    # Install dependencies\n",
    "    !pip install -q lion-pytorch tqdm pyyaml\n",
    "    \n",
    "    print(\"\u2713 Setup complete\")\n",
    "else:\n",
    "    import sys\n",
    "    sys.path.insert(0, 'src')\n",
    "    print(\"\u2713 Using local setup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  No GPU detected. Training will be slow on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.insert(0, 'src')\n",
    "\n",
    "from models import get_model, count_parameters\n",
    "from data import get_dataloader\n",
    "from optimizers import get_optimizer, get_scheduler, get_default_config\n",
    "from utils import MetricsLogger, set_seed, AverageMeter, accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "import json\n",
    "import os\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "print(\"\u2713 All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment settings\n",
    "CONFIG = {\n",
    "    'dataset': 'cifar10',        # 'cifar10' or 'cifar100'\n",
    "    'model': 'resnet18',         # 'resnet18', 'resnet34', or 'resnet50'\n",
    "    'optimizer': 'adam',         # 'sgd', 'adam', 'adamw', 'radam', or 'lion'\n",
    "    'epochs': 200,               # Number of training epochs\n",
    "    'batch_size': 128,           # Batch size\n",
    "    'seed': 42,                  # Random seed\n",
    "    'lr': None,                  # Learning rate (None = use default)\n",
    "    'weight_decay': None,        # Weight decay (None = use default)\n",
    "    'scheduler': 'cosine',       # 'none', 'cosine', 'step', or 'multistep'\n",
    "    'augment': True,             # Use data augmentation\n",
    "    'workers': 4,                # Data loading workers\n",
    "    \n",
    "    # For hypothesis testing\n",
    "    'label_noise': 0.0,          # Fraction of noisy labels (H3)\n",
    "    'data_fraction': 1.0,        # Fraction of training data\n",
    "}\n",
    "\n",
    "# Use default hyperparameters if not specified\n",
    "if CONFIG['lr'] is None or CONFIG['weight_decay'] is None:\n",
    "    default_config = get_default_config(CONFIG['optimizer'])\n",
    "    if CONFIG['lr'] is None:\n",
    "        CONFIG['lr'] = default_config['lr']\n",
    "    if CONFIG['weight_decay'] is None:\n",
    "        CONFIG['weight_decay'] = default_config['weight_decay']\n",
    "\n",
    "print(\"Experiment Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch:3d} [Train]', leave=False)\n",
    "    for inputs, targets in pbar:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc = accuracy(outputs, targets)[0]\n",
    "        losses.update(loss.item(), inputs.size(0))\n",
    "        top1.update(acc.item(), inputs.size(0))\n",
    "        pbar.set_postfix({'loss': f'{losses.avg:.4f}', 'acc': f'{top1.avg:.2f}%'})\n",
    "    \n",
    "    return losses.avg, top1.avg\n",
    "\n",
    "def validate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_loader, desc='[Val]', leave=False):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            acc = accuracy(outputs, targets)[0]\n",
    "            losses.update(loss.item(), inputs.size(0))\n",
    "            top1.update(acc.item(), inputs.size(0))\n",
    "    \n",
    "    return losses.avg, top1.avg\n",
    "\n",
    "print(\"\u2713 Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "set_seed(CONFIG['seed'])\n",
    "# Set device (support CUDA, MPS, and CPU)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load data\n",
    "print(f\"\\nLoading {CONFIG['dataset'].upper()} dataset...\")\n",
    "train_loader, test_loader, num_classes = get_dataloader(\n",
    "    dataset=CONFIG['dataset'],\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    augment=CONFIG['augment'],\n",
    "    num_workers=CONFIG['workers'],\n",
    "    data_fraction=CONFIG['data_fraction'],\n",
    "    label_noise=CONFIG['label_noise']\n",
    ")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Create model\n",
    "print(f\"\\nCreating {CONFIG['model']} model...\")\n",
    "model = get_model(CONFIG['model'], num_classes=num_classes).to(device)\n",
    "print(f\"  Parameters: {count_parameters(model):,}\")\n",
    "\n",
    "# Create optimizer\n",
    "print(f\"\\nCreating {CONFIG['optimizer'].upper()} optimizer...\")\n",
    "optimizer = get_optimizer(\n",
    "    CONFIG['optimizer'], model.parameters(),\n",
    "    lr=CONFIG['lr'], weight_decay=CONFIG['weight_decay']\n",
    ")\n",
    "print(f\"  LR: {CONFIG['lr']}, WD: {CONFIG['weight_decay']}\")\n",
    "\n",
    "# Create scheduler\n",
    "scheduler = get_scheduler(optimizer, CONFIG['scheduler'], CONFIG['epochs'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(\"\\n\u2713 Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': [], 'learning_rate': []}\n",
    "best_acc = 0.0\n",
    "\n",
    "print(f\"Training for {CONFIG['epochs']} epochs...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for epoch in range(1, CONFIG['epochs'] + 1):\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "    test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
    "    \n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['test_loss'].append(test_loss)\n",
    "    history['test_acc'].append(test_acc)\n",
    "    history['learning_rate'].append(current_lr)\n",
    "    \n",
    "    print(f\"Epoch {epoch:3d}/{CONFIG['epochs']} | \"\n",
    "          f\"Train: {train_loss:.4f} / {train_acc:6.2f}% | \"\n",
    "          f\"Test: {test_loss:.4f} / {test_acc:6.2f}% | LR: {current_lr:.6f}\")\n",
    "    \n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        print(f\"  \u2713 New best: {best_acc:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"Training complete! Best: {best_acc:.2f}% | Final: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "epochs_range = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "# Loss curves\n",
    "axes[0, 0].plot(epochs_range, history['train_loss'], linewidth=2, label='Train')\n",
    "axes[0, 0].plot(epochs_range, history['test_loss'], linewidth=2, label='Test')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curves\n",
    "axes[0, 1].plot(epochs_range, history['train_acc'], linewidth=2, label='Train')\n",
    "axes[0, 1].plot(epochs_range, history['test_acc'], linewidth=2, label='Test')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "axes[0, 1].set_title('Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Test loss detail\n",
    "axes[1, 0].plot(epochs_range, history['test_loss'], linewidth=2, color='red')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Test Loss')\n",
    "axes[1, 0].set_title('Test Loss (Detail)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate\n",
    "axes[1, 1].plot(epochs_range, history['learning_rate'], linewidth=2, color='green')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Learning Rate')\n",
    "axes[1, 1].set_title('LR Schedule')\n",
    "axes[1, 1].set_yscale('log')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f\"{CONFIG['optimizer'].upper()} on {CONFIG['dataset'].upper()} - Best: {best_acc:.2f}%\", \n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if IN_COLAB:\n",
    "    plt.savefig(f\"{CONFIG['optimizer']}_{CONFIG['dataset']}_results.png\", dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\n\u2713 Plot saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('results', exist_ok=True)\n",
    "exp_name = f\"{CONFIG['dataset']}_{CONFIG['optimizer']}_seed{CONFIG['seed']}\"\n",
    "results_file = f'results/{exp_name}_metrics.json'\n",
    "\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump({\n",
    "        'config': CONFIG,\n",
    "        'history': history,\n",
    "        'best_accuracy': float(best_acc),\n",
    "        'final_accuracy': float(test_acc)\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"\u2713 Results saved to {results_file}\")\n",
    "\n",
    "# Save model\n",
    "checkpoint_file = f'results/{exp_name}_model.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'best_accuracy': best_acc,\n",
    "    'config': CONFIG\n",
    "}, checkpoint_file)\n",
    "print(f\"\u2713 Model saved to {checkpoint_file}\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    files.download(results_file)\n",
    "    print(\"\u2713 Results downloaded\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}